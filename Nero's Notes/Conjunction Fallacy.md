# Conjunction Fallacy


> Merely corroborative detail, intended to give artistic verisimilitude to an otherwise bald and unconvincing narrative . . .
> —Pooh-Bah, in Gilbert and Sullivan’s *The* *Mikado*

The conjunction fallacy is when humans assign a higher probability to a proposition of the form “A and B” than to one of the propositions “A” or “B” in isolation, even though it is a theorem that conjunctions are never likelier than their conjuncts. For example, in one experiment, 68% of the subjects ranked it more likely that “Reagan will provide federal support for unwed mothers and cut federal support to local governments” than that “Reagan will provide federal support for unwed mothers.”[1](https://www.lesswrong.com/s/5g5TkQTe9rmPS5vvM/p/Yq6aA4M3JKWaQepPJ#fn1x7)

[A long series of cleverly designed experiments](https://www.lesswrong.com/lw/jj/conjunction_controversy_or_how_they_nail_it_down/), which weeded out alternative hypotheses and nailed down the standard interpretation, confirmed that conjunction fallacy occurs because we “substitute judgment of representativeness for judgment of probability.” By adding extra details, you can make an outcome seem *more* characteristic of the process that generates it. You can make it sound more plausible that Reagan will support unwed mothers, by *adding* the claim that Reagan will *also* cut support to local governments. The implausibility of one claim is compensated by the plausibility of the other; they “average out.”

**Which is to say: Adding detail can make a scenario sound more plausible, even though the event necessarily becomes less probable.**

If so, then, *hypothetically speaking*, we might find futurists spinning unconscionably plausible and detailed future histories, or find people swallowing huge packages of unsupported claims bundled with a few strong-sounding assertions at the center.

If you are presented with the conjunction fallacy in a naked, direct comparison, then you may succeed on that particular problem by consciously correcting yourself. But this is only slapping a band-aid on the problem, not fixing it in general.

In the [1982 experiment](https://www.lesswrong.com/lw/ji/conjunction_fallacy/) where professional forecasters assigned systematically higher probabilities to “Russia invades Poland, followed by suspension of diplomatic relations between the usa and the ussr” than to “Suspension of diplomatic relations between the usa and the ussr,” each experimental group was only presented with one proposition. What strategy could these forecasters have followed, as a group, that would have eliminated the conjunction fallacy, when no individual knew directly about the comparison? When no individual even knew that the experiment was *about* the conjunction fallacy? How could they have done better on their probability judgments?

Patching one gotcha as a special case doesn’t fix the general problem. The gotcha is the symptom, not the disease.

What could the forecasters have done to avoid the conjunction fallacy, without seeing the direct comparison, or even knowing that anyone was going to test them on the conjunction fallacy? 

**It seems to me, that they would need to notice the word “and.” They would need to be wary of it—not just wary, but leap back from it. Even without knowing that researchers were afterward going to test them on the conjunction fallacy particularly. They would need to notice the conjunction of *two entire details*, and be *shocked* by the audacity of anyone asking them to endorse such an insanely complicated prediction. And they would need to penalize the probability *substantially*—a factor of four, at least, according to the experimental details.**

It might also have helped the forecasters to think about possible reasons why the US and Soviet Union would suspend diplomatic relations. The scenario is not “The US and Soviet Union suddenly suspend diplomatic relations for no reason,” but “The US and Soviet Union suspend diplomatic relations for any reason.”

And the subjects who rated “Reagan will provide federal support for unwed mothers and cut federal support to local governments”? Again, they would need to be shocked by the word “and.” Moreover, they would need to *add* absurdities—where the absurdity is the log probability, so you can add it—rather than averaging them. They would need to think, “Reagan might or might not cut support to local governments (1 bit), but it seems very unlikely that he will support unwed mothers (4 bits). *Total* absurdity: 5 bits.” Or maybe, “Reagan won’t support unwed mothers. One strike and it’s out. The other proposition just makes it even worse.”

Similarly, consider Tversky and Kahnemans (1983) experiment based around a six-sided die with four green faces and two red faces. The subjects had to bet on the sequence (1) rgrrr, (2) grgrrr, or (3) grrrrr appearing anywhere in twenty rolls of the dice. Sixty-five percent of the subjects chose grgrrr, which is strictly dominated by rgrrr, since any sequence containing grgrrr also pays off for rgrrr. How could the subjects have done better? By noticing the inclusion? Perhaps; but that is only a band-aid, it does not fix the fundamental problem. By explicitly calculating the probabilities? That would certainly fix the fundamental problem, but you can’t always calculate an exact probability.

The subjects lost heuristically by thinking: “Aha! Sequence 2 has the highest proportion of green to red! I should bet on Sequence 2!” To win heuristically, the subjects would need to think: “Aha! Sequence 1 is *short*! I should go with Sequence 1!”

They would need to feel a stronger *emotional impact* from Occam’s Razor—feel *every*added detail as a burden, even a single extra roll of the dice.

Once upon a time, I was speaking to someone who had been mesmerized by an incautious futurist (one who adds on lots of details that sound neat). I was trying to explain why I was not likewise mesmerized by these amazing, incredible theories. So I explained about the conjunction fallacy, specifically the “suspending relations ± invading Poland” experiment. And he said, “Okay, but what does this have to do with—” And I said, “It is more probable that universes replicate *for any reason*, than that they replicate *via black holes because advanced civilizations manufacture* *black holes because universes evolve to make them do it*.” And he said, “Oh.”

Until then, he had not felt these extra details as extra burdens. Instead they were corroborative detail, lending verisimilitude to the narrative. Someone presents you with a package of strange ideas, *one* of which is that universes replicate. Then they present support *for the assertion that universes replicate.* But this is not support for the [package](http://en.wikipedia.org/wiki/Package-deal_fallacy), though it is all told as one story.

You have to disentangle the details. You have to hold up every one independently, and ask, “How do we know *this* detail?” Someone sketches out a picture of humanity’s descent into nano-technological warfare, where China refuses to abide by an international control agreement, followed by an arms race . . . Wait a minute—how do you know it will be China? Is that a crystal ball in your pocket or are you just happy to be a futurist? Where are all these details coming from? Where did *that specific* detail come from?

For it is written:

> *If you can lighten your burden you must do so.*
>
> *There is no straw that lacks the power to break your back.*