# [[Scuttleblurb]] on [[Microsoft]]


There’s a good reason why Microsoft was dubbed the Death Star by many fearful detractors during the on-premise era: its OS/application stack, with 90%+ desktop share, was an impermeable force that whipped the surrounding computing galaxy into submission.  Given Window’s ubiquity, value added resellers and systems integrators optimized their resources and relationships by supporting Windows applications. Third party developers had little choice but to create applications compatible with Windows because Windows was standardized on PCs, the primary node through which consumers accessed applications.  Windows was the ultimate platform before that word became bastardized…it just happened to be the wrong platform for a world that was shifting to mobile and cloud!  But a fundamental change in how applications are distributed and consumed – the transition from on-premise, device-specific licenses to user-specific cloud-hosted subscriptions accessible on any device – have reoriented the competitive landscape.

Azure was released in early 2011 during Ballmer’s tenure as CEO under the name “Windows Azure”, which tells you something about where the company’s priorities were at at the time.  But Microsoft’s OS agnostic orientation really started with current CEO Satya Nadella, who in January 2011 took over the Servers and Tools Business from whence Azure sprung and, against great resistance from a team that was winning with on-premise server products, reset the group’s priorities.  In fact, if you view some of the “Azure Fridays” videos that Microsoft uploads to YouTube, you’ll see that some of the demos are done on a Macbook.  _\[“OS agnostic” is a bit misleading as the company has recently started re-bundling Office/EMS with Windows (Microsoft 365), but what I mean is that the customer can choose this bundle or not.  Microsoft’s applications are no longer predominantly captive to Windows\]._ 

_\[The tech nobility – not just software incumbents like Microsoft, Oracle, and Salesforce.com but behemoths with major infrastructure and machine learning chops like Amazon and Google – play on multiple layers of the enterprise computing stack (mission critical applications, developer tools, storage, processing), but spread out from somewhat different origins.  AWS extended its reach from IaaS to PaaS, Microsoft from PaaS/SaaS to IaaS, Salesforce from SaaS to PaaS.  The distinctions between some of these layers are sort of fuzzy but still useful to hold in your mind.  If you aren’t familiar with those acronyms you might find **[this post](https://azure.microsoft.com/en-us/overview/what-is-paas/)** helpful\]._ 

![](https://www.scuttleblurb.com/wp-content/uploads/2018/01/msft_1-1024x868.png)

An enterprise computing moat is no longer defined by forced lock-in to proprietary platforms.  Windows OS has increasingly become a sideshow; 1/3+ of Azure’s virtual machines are Linux-based; a growing amount of app development is open-source; nearly 70% of O365’s ~150mn consumer and enterprise subs have the application deployed on Android and iOS; Active Directory, Microsoft’s user account management and credentialing platform, can be connected to AWS and Google Cloud resources.  Supplanting the closed model is a cat’s cradle of portable applications touching several disparate hosting and development environments.  Rather than dominate distribution channels, suffocate competitors, and extract surplus from reluctantly captive customers, the new way to moat is offering fertile soil for others to grow, splaying the indispensable infrastructure upon which other enterprises land, build, and dispense their core applications.  Any semblance of “lock-in” comes from delighting demand (enterprises and developers) with useful tools and abstractions, not controlling supply (integrators and OEMs) with heavy-handed incumbency.  I’ve touched on the “infrastructure” theme before in a prior post in the context of the payments space:

_“V’s open partnership model is a major change.  VisaNet, as sophisticated and broad as it is, operated as a tightly restricted network with unidirectional flows (pulling money from one account and moving it to another) and limited functionality for those accessing it for most of its life.  But now Visa has modularized its network (management actually began talking about this as early as 2010), decomposing VisaNet into its core building blocks, providing a set of APIs (over 60 web services/APIs available through a developer portal that launched in 2016) that financial institutions, platform operators, and payment enablers can use to interface with Visa’s network and services to create a wide variety of interoperable solutions……Visa and Mastercard are entrenching themselves as the very first layer of disintermediation, the basic and indispensable infrastructure underlying the entire payments ecosystem, whatever the country, whatever the medium.  And it seems increasingly the case that various payment providers will just plug into V/MA’s secure pipes while they themselves work on improving the customer experience.”_

I similarly view Azure, GCP, and AWS as utilities underpinning all sorts of unpredictably cool shit that others will build.  But taking on this role also presents the challenge of how to claim value when no one is really forced to use your toolkit.  An extension of disruption theory (as expounded upon in [Christensen’s _The Innovator’s Solution_](https://www.amazon.com/Innovators-Solution-Creating-Sustaining-Successful/dp/1422196577)) is helpful here: integrated architectures, made up of tightly unified proprietary _inter_dependent components are best suited to optimize performance and tend to dominate until a product becomes functionally “good enough” to meet the market’s needs, at which point other vectors of competition – convenience, flexibility, speed to market – become more important and call for standardized, independent pieces that comprise a modular architecture.  So, in the context of computing, consider (broadly) the trek from mainframes _\[chips, hardware, operating system, and applications all fused together\]_ to Wintel _\[hardware and chips modularized but OS and applications integrated\]_ to enterprise cloud _\[hardware, chips, OS, and applications all modularized\]_

Venture capitalist Bill Gurley and tech writer Ben Thompson have also both written about the benefits of hardware/software integration, [here](http://abovethecrowd.com/2003/02/10/software-in-a-box-the-comeback-of-the-hardware-based-business-model/) and [here.](https://stratechery.com/2017/arcore-googles-benefit-to-apple-ars-killer-app-and-apples-business-model/)

And increasingly, even the applications themselves are diaggregated into independent functions that communicate through APIs.  In fact, entire multi-billion dollar companies like Stripe, SendGrid, and Twilio have been built around functions – payment processing, email, push alerts – that are shared across many different applications.  Disaggregation is taking hold on the development side too.  Containers let you pack everything you need to run an application – code, dependencies, libraries – into, um, “containers” that can be moved to and quickly deployed on various computing environments.  They have become increasingly popular because they enable microservices architectures, wherein a single, unwieldy “monolithic” application is broken down into smaller containers, each container independently executing a specific process – delivering a page, storing messages, accepting orders – as part of delivering a seamless application user interface.  You can develop, debug, and test a single containerized application without effecting all the other containers and do it all much more quickly and agilely than you could in a traditional virtualization scheme, which matters considering the hastening rate of innovation and change in application development today.  And you can do this all with fewer computing resources than required under a traditional virtualization apparatus, which, unlike containers, still tethers the application code to a specific operating system _\[and so, under virtualization, if you run multiple applications, you will have multiple “guest” operating systems that each have to boot before communicating with a single “host” operating system, which is burdensome compared to having multiple “containerized” applications communicating with a single host OS\]_.

But in an increasingly modularized computing environment, how is stickiness got?  Well, you can introduce higher level abstraction.  Okta is trying to claim the critical point of integration across cloud computing by owning user identities and rendering them portable across cloud stacks and across applications on those cloud stacks.  With respect to containers, AWS tried exploiting its 7-year head start in enterprise cloud to attempt infrastructure lock-in by providing a container orchestration service that made it easy to manage and scale microservices on AWS and AWS only.  That is, until Google – in an effort to draw customers onto its own cloud and to presumably preempt AWS lock-in – open-sourced Kubernetes in 2014.  Kubernetes enables microservices – the containers holding the application plus the necessary adjoining feature sets like autoscaling, load balancing, and database discovery – across all the major public clouds and on-premise by translating into a common language all the different ways these computing environments implement microservices _\[known as Borg before being open sourced, Kubernetes orchestrated the microservices underlying Gmail, search, and maps\]_.  It also displays in real time all the applications being run and the computing resources each application is consuming across computing environments.

Setting up and running Kubernetes was super easy on Google Cloud but onerous on Azure and AWS until just recently, when [Amazon](https://aws.amazon.com/about-aws/whats-new/2017/11/introducing-amazon-elastic-container-service-for-kubernetes/) and [Microsoft](https://azure.microsoft.com/en-us/blog/introducing-azure-container-service-aks-managed-kubernetes-and-azure-container-registry-geo-replication/), witnessing Kubernetes’ torrid pace of adoption, grudgingly (I assume) joined the bandwagon.  They are now dedicating resources that make it far easier than before to set up, manage, and operate Kubernetes environments.  So now that Kubernetes is deployed with increasingly comparable ease across Google Cloud, AWS, Azure, on-premise, wherever, no single cloud vendor has lock-in on microservices-based application development.

In the same vein of open frameworks, about a year after Kubernetes, Google open-sourced its machine learning software, TensorFlow, which has since become the most popular machine learning repository on GitHub.  Microsoft and Amazon have also made their internal machine learning tools available to wider developer community, the two companies jointly developing a deep learning API, Gluon, that can be used by third party developers to build machine learning models using preconfigured components.

What is the point of all this? Why open source at all?  Why foster adoption on a platform that you don’t own?  Well, there are intrinsic benefits: open-sourcing exposes internal tools to much more rapid iteration and development, which in turn allows Google and others to strengthen internally developed applications built using those same tools.  But, at least as importantly, open sourcing can ironically promote lock-in if you own the thing that best optimizes the platform being open sourced…to wit, TensorFlow’s open sourced machine learning frameworks being paired with Google’s proprietary neural network ASICs.  Last May, Google released the 2nd generation of Tensor Processing Units, uber high performance chips designed to optimally run TensorFlow _\[TPUs power AlphaGo, Google Translate, and Google Photos\]_.  These chips proliferate the company’s datacenters and can be used by enterprises to both train and run their algorithms.  By making TensorFlow widely available and easily accessible , and encouraging the developer community to co-opt the company’s internal protocols as the industry standard, Google strengthens its own hand since, [by virtue of TPU integration, its cloud can host that standard better than anyone else](https://www.theverge.com/circuitbreaker/2016/5/19/11716818/google-alphago-hardware-asic-chip-tensor-processor-unit-machine-learning).  Reintegration does not contradict the point about modularity.  It’s just that, with respect to machine learning, performance, rather than flexibility, is still the critical vector of competition.  _\[The Kubernetes case was different: open sourcing here was about neutralizing lock-in by the industry leader (Amazon), which was far more important than creating switching costs of its own by keeping Kubernetes proprietary.\]_  

Furthermore, it’s not as though Google gave away the keys to its kingdom by open sourcing TensorFlow.  As we all know by now, the real point of leverage in machine learning comes not so much the algorithms themselves, but from the quality/quantity of proprietary data and the immense processing power required to train the algorithms.  These two factors constitute a serious moat for the full-stackers.  The entry barriers are huge.  Hyperscale incumbents are continually marching down the learning curve and lowering their units costs as they secure more volume, making it difficult for new entrants to capture the threshold market share necessary to justify vast investment in infrastructure and engineering talent.

Some have pointed to ricocheting infrastructure price cuts among the big 3 as the nascent signs of eventual commodification.  This view stems partly from the notion that cloud computing simply means porting on-premise workloads to new venues, and consuming compute and storage under a new model that reduces operating costs and improves efficiency.

As I previously wrote: _“Public clouds tightly match computing resources to actual usage (buying by the millisecond), eliminating the explicit costs of idle capacity and the opportunity costs of insufficient scale; obviate investment in expensive, in-house IT personnel to manage on-premise servers; reduce the latency of globally delivered apps (delivered, as they are, from globally distributed infrastructure), allowing companies to focus their limited resources on their core business”._

So, for instance, some [remarks from Neil Hunt, Netflix’s Chief Product Officer](https://www.quora.com/Why-do-large-websites-such-as-Reddit-and-Netflix-use-AWS-to-host-when-self-hosting-would-be-cheaper):

_“We operate out of 12 different AWS datacenters for redundancy and resiliency, and our footprint in each is actually not that large.  We share AWS operational staff with hundreds of other businesses in each DC, which means they can be more specialized and much more cost-effective than if we had to have all those roles dedicated to just Netflix._

_We achieve utilization well over 50% on all our AWS hardware – because we lease it only when we need it, and give it back off-peak.  Utilizations of 20% would be pretty normal in self-hosted data centers.  In addition, AWS manages the growth space for us out of a giant pool.  If it were our own datacenters, it would be hard for us to expand a contiguous cage of servers every year for growth, necessitating discontiguous clusters of machines and all kinds of challenges in networking, connectivity, security, etc.”_

And this is all valid…it’s just too narrow.  Isolating the IaaS isn’t the right way to evaluate these cloud stacks.  While it is often the initial draw, higher value machine learning, analytics, and development tools at the platform and application layers weave themselves into a more complete solution set over time.  Integration between the different layers is what creates differentiation and introduces switching costs, per Google fusing its TensorFlow platform with TPU-powered datacenters.  All three parts – IaaS, PaaS, SaaS – must be considered as a whole, as they are used holistically in practice (more below).

And besides, despite persistent price cuts in infrastructure services by major cloud vendors and the commodification fears they’ve inspired, gross margins for Microsoft’s commercial cloud have expanded by 6pts y/y and 3pts q/q to 51% in the latest quarter and margins are, in fact, expanding across each layer, including Azure, where revenue has just about doubled y/y over each of the last several quarters and have grown much faster than AWS.  It appears that Amazon’s success in e-commerce has prompted some enterprises to dual source cloud vendors.  Per one anecdote in a recent survey of 34 Microsoft partners by JP Morgan:

_“Azure stands out as the most positive topic in the survey and across all the deep-dive checks, with one partner indicating that currently 60% of his cloud migration opportunities are for Microsoft Azure and only 35% for Amazon AWS vs. a complete opposite mix a year ago.  Another partner who works with Global 2000 companies is noticing that after the Amazon/Whole Foods deal, all retail companies have ‘kind of issued a ban on using \[Amazon\] AWS’ and are moving to Microsoft Azure in droves.”_

There’s less lock-in in today’s cloud paradigm, so I can’t really argue that Microsoft’s moat is as strong as it was during the Wintel era.  But, the market opportunity today is so much huger today that even with its narrower moat, I think Microsoft’s value capture opportunity is net greater.  The use cases are so multifaceted and vast that it’s hard to circumscribe the addressable market opportunity with a high degree confidence, though management will loosely say $4.5 trillion, perhaps anchoring to today’s $3tn in ex. device global IT spend, which if true presents an enticing growth opportunity for the big 3 hyper-scale vendors, whose combined run-rate cloud revenue amounts to a “mere” ~$50bn.  Compare this multi-trillion dollar figure against Microsoft’s $25bn TAM from the mid-90s, which consisted of a PC + Windows on every desk, or its $250bn TAM in 2005, when it expanded into datacenters.

It’s hard to think of an industry that won’t require insights pulled from the passive collection and real time analysis of vast quantities of data; for many sectors – logistics, auto, medicine, farming, manufacturing, retail – this will be banal stitching in the industry fabric.

Here are some current use cases:

a) Land-O-Lakes, a farmer-owned coop, recently loaded decades of satellite imagery for all the farms they support onto Azure and used Azure’s AI to predict the volume of seeds and varieties of fertilizer treatments that would maximize yield on each plot of land, loading these insights into the semi-autonomous John Deere tractors used in variable rate seeding (customizing seed volume to local plot conditions), boosting crop output by 3x-5x.  Microsoft’s HoloLens technology (a mixed-reality holographic computer headset) is used by farmers in remote parts of the world to compare crop output scenarios.  With these new capabilities, Microsoft is generating twice as much revenue from Land-O-Lakes than before.

b) Rolls-Royce’s “power by the hour” model, whereby airline customers pay per engine flying hour, places the burden of managing engine reliability with RR. Engines wirelessly download telemetry in heavy volume to Azure servers, which is analyzed and modeled with Microsoft’s Cortana Intelligence Suite _\[machine learning and analytics, among other things\]_ to detect anomalies in aircraft and engine parts, reducing the cost of maintenance and improving uptime.

c) The Real Madrid football club hosts its mobile interactive video app, created using Visual Studio, on Azure Media Services and uses Azure Active Directory B2C to authenticate registered users.  User behavior on the app like check-ins, ad clicks, and profile updates are collected in Azure Data Factory (data movement service) and published to a SQL database, where it can be accessed by Excel and Power BI (Analytics) subscribers and used to offer targeted, customized ads.  In the future, Real Madrid plans to use Azure Machine Learning to predict seat pricing.

d) Microsoft Studios, the segment responsible for publishing games for Xbox and Windows, designed an analytics platform on Azure Event Hubs, a data streaming platform that can ingest millions of events per second from games being played on multiple devices, structuring the data for consumption by Azure Machine Learning (to detect player cheating) and by Power BI (to capture performance indicators like daily active users).  Halo generates hundreds of billions of game events in a given day from millions of players at once and all that telemetry needs to be processed at sub-second latency and collected and analyzed without degrading the player experience.

All this good shit was inconceivable just a decade ago and goes well beyond the provision of “mere” computing resources _\[though of course, none of this would be possible without Microsoft’s formidable processing power\]_.

_Office and the power of incumbency_

Up to this point, I’ve only touched on the platform and infrastructure layers.  As cloud native organizations, this is where GCP and AWS predominantly play.  But Microsoft is a different animal.  Because of its dominant Office suite in the pre-cloud era, Microsoft’s cloud stack is SaaS heavy. _\[Microsoft doesn’t separately disclose revenue by cloud layer but my best guess based on market share estimates from Synergy Research Group is that of its $20bn Cloud ARR, only an estimated $5bn-$7bn of that is IaaS + PaaS vs. AWS’s $18bn ARR.  The rest of is Office 365, Dynamics 365, and other SaaS properties with resilient and growing profits streams.\]_  As I’ve explained, switching costs are not what they once were.  Microsoft can no longer strictly bundle its applications to a dominant Windows franchise. Office’s days of 95% market share are likely over.  And yet, it would be a mistake to simply dismiss the benefits of incumbency.

Office 365 was released in June 2011, more than 4 years after Google Docs/Sheets/Slides.  While some have portrayed Office’s tardy arrival to the cloud as a classic instance of a lumbering incumbent lazily moored to its antiquated ways, in this thought provoking [blog post](https://hackernoon.com/complexity-and-strategy-325cd7f59a92), 20+ year Microsoft vet Terry Crowley takes a different point of view, arguing that Microsoft was well-attuned to Google’s machinations but that replicating the simplicity of Google Docs straight away – rather than taking the time to build a “Word Web App” compatible with existing file formats – would have meant forsaking the complexity embedded in and enabling its highly functional native suite, the very complexity at the heart of its competitive advantage (emphasis mine):

_…the performance challenges with running large amounts of code or large data models in the browser and managing the high relative latency between the front and back end of your application generally make it harder to build complex applications in a web-based environment. **Hyper-ventilation by journalists and analysts about the pace of Google App’s innovation generally ignored the fact that the applications remained relatively simple.**_

 _it was clear that \[Google was\] using an asymmetric technical attack of leveraging their simplicity to deliver sharing and co-editing features. These features were clearly differentiated and would be immensely hard to deliver on top of the existing highly functional (large N) Office apps. As we started building the web apps, we needed to decide whether we were going to “walk away” from our own complexity like we had when we developed OneNote or embrace the existing complexity, with the costs and constraints that that would imply for future development._

**_The final decision to build the “Word Web App” rather than “a new web-based word processor from Microsoft that is not fully compatible with Word” (and similarly for Excel, PowerPoint and OneNote) was strongly driven by the belief that the file formats continued to serve as a critical competitive moat with immensely strong network effects._**_**It is now ten years later. Office has full platform coverage with native applications on all devices and highly functional and compatible web applications. These all support sharing, co-authoring and offline use. Full real-time co-editing is being rolled out now and was as hard to implement in the native applications as we had expected. Real-time co-editing, to the extent it is used and valued, reinforces the file format moat since it is technically implausible to imagine two independent implementations with different underlying data models achieving that fine degree of real-time interoperability.** The Office implementations highly leverage shared code implementations of the core engines across both native and web clients to achieve that interoperability._

C_ompetitive strategy argues that when a competitor attempts to differentiate you need to focus on neutralizing that differentiation as quickly as possible. The path we took did not accomplish that. Google was able to establish a critical competitive beachhead by building on their differentiation. I think it is still too early to see how this will all play out. **It is clear the Office apps would not be positioned functionally the way they are now (with fully compatible native and web clients on all devices and support for offline and co-editing) if there had been any squeamishness about embracing the challenges of complexity. That complexity (as it embodies valued functionality) is the moat**._

When Terry refers to complexity as a competitive advantage, he is alluding to the integration/modularity concept I touched on above…except he’s not talking about vertical integration across the value chain but rather integration between Office’s on-premise instantiation, with its near 100% capture of productivity applications, and the new cloud-hosted version.  There’s a whole generation of knowledge workers who have habituated themselves to Microsoft products and are now carrying those habits into the cloud.

In a big way.  I mean, just look:

![](https://www.scuttleblurb.com/wp-content/uploads/2017/12/msft_4-1024x547.png)

Source: Okta

Microsoft’s deeply entrenched position within the enterprise easily carried over to the cloud, where the company gained scale almost immediately.  Within the first 18 months of Satya’s assuming the CEO role in 2014, Office 365 went from the fourth most provisioned enterprise cloud app (behind Salesforce.com, Box, and Google Apps, in that order) to the first, overtaking Google Apps sometime in mid-2014.  Four years after launch, Office 365 was adopted by 4 out of 5 of the Fortune 500 with over half of the installed base on premium workloads.

Enterprise Office 365 subs have doubled over the last 2 years to >120mn, and 40%+ O365 revenue growth – gotten through a combination of installed base penetration, ARPU gains, and premium services upsell – has more than offset declines transactional licensing volumes, resulting in net overall on-premise + cloud Office suite revenue and seat growth of +hsd y/y over the past few quarters.  Last quarter, O365 revenue surpassed revenue from the traditional licensing business for the first time and with only about half the Office commercial installed base on O365, there’s still a ways to go.  Cloud subscription growth has been so strong that despite swapping 90%+ gross margin on-prem licenses for much lower margin (~60%) cloud subscriptions, profits from Microsoft’s Productivity and Business Processes segment (ex. LinkedIn) accelerated to low-teens growth in the most recent quarter.

But despite this success, Google’s productivity suite whiffs of low-end disruption.  An incumbent, which over the years targets ever bigger and more profitable opportunities at the higher end of the market, finds itself culturally and organizationally ill-equipped to serving the lower-end, which is now claimed by new entrants, who eventually get so good at what they’re doing that they eventually migrate upstream and encroach upon the incumbent’s domain.  Google’s light weight web-based productivity suite simply could not (and still can’t) handle the heavy duty demands of large enterprises, which allowed Microsoft to keep its enterprise relationships at the early stages of its cloud transition.

If there were no feedback loops from machine learning, one could argue that it would just be a matter of time before Google improved its capabilities enough to creep into Microsoft’s enterprise accounts.  But a mitigating factor here is that client engagement with the Office suite creates captive, proprietary datasets – Microsoft’s cloud collects tens of billions of signals every day from its productivity suite, everything from who you share documents with and when to how long you read certain emails serves as a signal – that feed machine learning algorithms, honing relevance and driving engagement, which engagement in turn generates more data in a self-reinforcing loop that makes the product user-specific and sticky.  Engagement created burgeoning datasets and client habituation, providing the foundation for more premium upsells infused with business analytics and advanced security features: premium subs now make up over 60% of O365 Enterprise suite, with increased adoption of the premium “E3” _\[E1 + document management + collaboration tools like Microsoft Teams and Skype Conferencing\]_ version driving most of the ARPU lift over the last 3 years, and “E5” _\[Windows E3 + souped up security + business analytics\]_ now taking root.  Hence why we’ve seen O365 revenue growth outpace seat growth over the last 2 years.

![](https://www.scuttleblurb.com/wp-content/uploads/2017/10/msft5.png)

To cite a specific example of how intelligence comes into play, here’s a hypothetical that MSFT’s Office Product Group gave at the UBS Technology Conference on Nov. 16. 2016:

_Let’s say you’re editing a document in Word and you’re preparing a report and then you think maybe I want to reuse a chart from a report I had seen somewhere in my work group and you didn’t quite remember who had shared this with you, but you want to use one of those charts. So what we have today as a feature now in Office 365 is called Word Tap._

_So you’ll literally one tap onto the ribbon and we use the AI technique to bring all the relevant documents that you’ve seen in the past that may be interesting to the content that you’re writing now, and we auto-bring those things into you right pane. You can scroll in the right pane. You can tap on the chart that you see, and boom, it’s in your Word document.  And so instead of leaving Word, going and doing a search, find\[ing\] the filter you searched on, remember\[ing\] who sent you that thing, the AI signal brings it back into Word._

Power Point’s Presentation Translator add-in will recognize your voice and throw up subtitles in one of over 60 different languages in real time as you give you your presentation in front of an audience…and any audience member with the Microsoft Translator app (on iOS, Android, or Windows) can have the presentation transcribed in her own language on her smartphone or tablet.  And these apps – Exchange/Outlook, Dynamics, Office, and LinkedIn – integrate with one another…contacts from Dymamics CRM are automatically synced to Outlook and vice-versa; CRM lists can be export to Excel, edited, and saved back to CRM; CRM data can populate templates crafted in Word, edits in Word can be published to CRM; email conversations in Outlook can convert into video chats on Skype within the same interface; connections between your co-workers and your sales leads are discovered in LinkedIn and surfaced on Sales Navigator (“social selling”) dashboard that is embedded within your Dymamics 365 interface; potential leads identified through Sales Navigator can be saved directly into your CRM, etc.

These applications get entangled with platform products, creating still more stickiness.  Once a client moves off-premise, cascading product adoption tends to kick in.  Just as TensorFlow and TPUs act as an important integration point to foster captivity for Google, dependencies from the Wintel era similarly function as customer flytraps.  An enterprise that rolls out Office 365 across its organization also ports users into the Azure Active Directory _\[an identity management system with security and usage monitoring functions that gives employees single sign-on access to in-house and third party SaaS applications like Concur, Salesforce.com, and DropBox.  AD is Microsoft’s most significant PaaS offering\]_, and expands from there to the full Enterprise Mobility Suite (tools to manage and secure devices).  The Power Apps that you would use to extend O365 are the same ones you’d use to extend Dynamics 365, and they can all be shared throughout the organization and edited by others on SharePoint.

And once a client’s user population and the critical productivity apps they consume throughout the day are nested at Azure, it’s a small step to accessing developer tools at Azure Marketplace, creating web/mobile app backends in Visual Studio _\[“Office 365 for developers”\]_ for whatever platform/device integrates with and taps into data from Office 365, Dynamics, or 3rd party apps like SAP, Salesforce, and Oracle.  Indicative of infectious product uptake, Azure + Office 365 enterprises consume 8x more Azure than other customers; greater than 70% and 60% of the Fortune 500 have 2+ and 3+ Microsoft cloud offerings, respectively.

So, in short, there are multiple products webbing the customer.  Machine learning makes these products increasingly useful and sticky in their own right but especially so when bundled across applications, which in turn spurs adoption vertically down the stack. _Yea, but…_

_Yea, but…_

Google’s productivity suite dominates the realm of early education.  I think this is a big deal.  Just as cloud native software upstarts like Slack and Atlassian have bypassed CIOs and targeted small teams within the enterprise, so too has Google circumvented school administrators, turning an army of teachers and principals into proselytizers who are habituating a whole generation of future white collar workers to the Google suite.  According to this [New York Times article](https://www.nytimes.com/2017/05/13/technology/google-education-chromebooks-schools.html?rref=collection%2Fsectioncollection%2Ftechnology&action=click&contentCollection=technology&region=rank&module=package&version=highlights&contentPlacement=1&pgtype=sectionfront):

_Today, more than half the nation’s primary- and secondary-school students — more than 30 million children — use Google education apps like Gmail and Docs, the company said. And Chromebooks, Google-powered laptops that initially struggled to find a purpose, are now a powerhouse in America’s schools. Today they account for more than half the mobile devices shipped to schools._ 

The below time series shows the number of laptops, tablets, and mobile devices shipped to US schools, which bears a resemblance to the above chart, except that Google and Microsoft have swapped places.

![](https://www.scuttleblurb.com/wp-content/uploads/2017/05/msft_1q172.png)

There is already a generational bias; companies with millennial workforces are 55% more likely to use Google Apps over O365 (per [Better Cloud Monitor)](https://www.bettercloud.com/monitor/google-apps-vs-office-365/). Relatedly, while Microsoft may have a strangle hold on large enterprise (1,000+ employees), Google maintains a slight edge over Microsoft among small businesses (in 2015 anyways).  Over time, small businesses become big businesses, big businesses become oblivious, young employees become senior execs who set the organizational tempo, and Google Apps capabilities will mature in step.

Furthermore, traditional barriers to breaching the enterprise are crumbling, yielding entry to upstarts who, drawing lessons from the consumer world, offer addictive, low-priced enterprise applications.  By de-risking experimentation of new user-friendly applications, which can be downloaded for free and trialed by small work teams, cloud hosting has upended a traditional enterprise sales process that required talking the CTO into an expensive and time-consuming enterprise-wide integration.  Slack’s success (5mn+ daily active users) in the enterprise would have been unimaginable a decade ago.  Now it seems the company has its sights on leveraging its addictive messaging app to act as a portal to instances of other apps.  Facebook At Work, Atlassian, and a host of new entrants (ChatWork, Hall, Honey, Quip) are using habitual interface engagement with a social/collaboration crux to breach the enterprise.  I can extrapolate a scenario in which a few of the native cloud startups extend that collaboration angle to owning the single sign-in portal (Atlassian is already doing this), acting as the engagement layer sitting atop an enterprise’s entire suite of mission critical apps (one app to rule them all), their integrations becoming ever more critical as users populate them with data.

For now, I mostly see the relationship of cloud-based, collaborative workflow management applications to Microsoft as both a complementary rather than an existential threat to the personal applications that run beneath.  Moreover, Microsoft is integrating its own messaging and collaboration features into O365, recently launching Microsoft Teams, incorporating it into even the basic version of Office.  80% of the Fortune 500 and 100mn O365 enterprise subs – with more and more of the 1bn+ total Office users converting to cloud every quarter – is a strong base on which to build.  It took Slack 3 years after launch in Feb 2014 to get 1.5mn+ paid user accounts.  With a flip of the switch, Microsoft Teams is available to 100mn subs in 18 languages across 180 countries with 150 different possible integrations.  Such is the power of incumbency and scale.

However, I must say that the more I learn about Atlassian products and organize my life on Trello, the less sanguine I am about its merely complementary role to personal applications, and the more I think about its disintermediating impact.  Atlassian is a very impressive company that I will write more about next month.  For now, I will simply note that feature sets and even its accompanying bundle of ancillary products is not the right frame to think about competitive dynamics.  It’s the _flow_ within which those features are embedded that matters and Atlassian has executed masterfully.

And so, while Microsoft is thriving today, it seems they are being buffetted on two sides of the stack simultaneously: from a possibly superior integrated machine learning offering at the middle and from disintermediating competition at the top.

Another supposed threat to cloud vendors is “edge computing” (“intelligent edge” in Microsoft-speak), where data is processed and analyzed (“edge analytics”) at the edge of a network where it is actually gathered, rather than relayed to a centralized cloud hub.  Cutting latency by bringing intelligence directly to the device is relevant to a host of applications – autonomous driving, industrial automation, healthcare, oil and gas drilling – where near-instantaneous processing and action is critical and the bandwidth constraints of moving persistently massive volumes of data from device to cloud are too onerous.  To draw an example from Microsoft’s recent Build developer conference – where the company showcased Azure IoT Edge, a Windows/Linux solution set that enables AI and analytics at the edge _\[and uses the same code running in the cloud, obviating the need to write a separate script\]_ – Sandvik uses Azure IoT to cut the time it takes to detect problems with its precision metal-cutting machines from 2 seconds (the time it takes for telemetry from the device to be shot to the cloud, analyzed, and delivered back down to the device) to ~100 milliseconds, avoiding costly, cascading failures.

Edge computing is an extension of, not a replacement for, cloud computing in centralized datacenters (ham-handed titles like “[Edge Computing Will Blow Away The Cloud](http://www.cio.com/article/3176036/it-industry/edge-computing-will-blow-away-the-cloud.html)” notwithstanding), which latter still do the heavy lifting of training and testing machine learning algorithms before those algos are exported to the device.  And in any case, despite intimations of Edge’s existential threat to GCP, AWS, and Azure cloud businesses, the latter 3 seem best positioned to offer modular solutions for edge computing (they already are).  Their customers have already built applications on their platforms and will simply port that code to the edge.

_Cats and dogs_

At only $9bn in profitable revenue, gaming is less than 10% of Microsoft’s revenue, but with an engaged user base growing 5%-10%/year, I think XBox is reasonably well positioned in a $100bn gaming market and, perhaps just as importantly, Xbox’s PC player community helps support another important Microsoft franchise: Windows.  XBox Live’s avid 53mn active users are part of the reason why Windows for the consumer market has actually been holding up better than the consumer PC market.  While certainly no longer the crux of Microsoft’s competitive advantage, Windows is still a highly profitable $15bn revenue business found in 500mn active devices that has, believe it or not, been growing by low-single digits y/y in recent quarters, outpacing the overall PC market.  I see Windows as a flat annuity whose relevance and growth could be reinvigorated at some point if mixed reality becomes a major computing platform, even if only in the enterprise \[[companies are collaborating in interesting ways using Microsoft’s untethered mixed reality computer, Hololens\]](https://blogs.windows.com/devices/2017/09/20/ford-brings-microsoft-hololens-to-design-studio-drives-speed-creativity-and-collaboration/).

You may be surprised to know that Bing’s $6bn of revenue has doubled from 3 years ago and has been growing by low-double digits y/y over the last year.  While I don’t know a single person who regularly searches on Bing (or consistently dual homes Google/Bing for that matter) and I only sometimes use it by mistake when forced to open an IE browser, Bing apparently has [33% search share in the US](https://gizmodo.com/microsoft-bings-us-market-share-is-wildly-underestimat-1798053061).

Doing a sum-of-the-parts is tempting but somewhat fraught with inconsistency since you can’t really talk about a company’s mutually reinforcing solution set and then proceed to value each element in the set separately.  For instance, the Bing and Cortana product teams are integrated, both services are infused within Office 365, and Office 365 engagement makes Cortana smarter, which renders the productivity suite more useful, stoking further engagement.  Bing’s market share is almost certainly depends on its default setting on Internet Explorer, which latter comes pre-loaded onto Windows.

But taking a step back, across all its businesses, Microsoft does $97bn in revenue.  If Microsoft’s identity during the 1990s was firmly anchored to Windows, today it is nebulously dispersed in AI and (still) most significantly instantiated in a productivity suite doing $25bn in revenue, growing high-single digits annually.  The commercial cloud properties – O365 Commercial, Dynamics 365, Azure – have been collectively growing by 50%+ y/y and are run-rating at $20bn revenue and $10bn in gross profits with a still substantial opportunity for competitively advantaged growth, even as the legacy licensed businesses bleed away.  It would not surprise me to see Microsoft pulling $120bn in revenue and $70bn in gross profits from its commercial cloud stack in 10 years.

And then on top of that, there will be several businesses heaping several 10s of billions in revenue.  Windows isn’t lighting the world on fire and maybe it never will again, but I think it at least floats along at $15bn-$20bn/year, buoyed by XBox, AR/VR, IoT, and some re-bundling efforts with Office.  In a decade, Bing will probably be a $10bn business; XBox will be closer to $20bn.  LinkedIn, which is doing around $4bn in revenue today and killing it _\[sent message +65% y/y, feed updates +60%, sessions +20%\]_ will grow to at least ~$15bn, reinforcing the stickiness and appeal of Dynamics 365 in the process.

Surface has grown from less than $2bn 3 years ago to $4.6bn today, and while hardware is obviously not Microsoft’s focus, it serves as a test bed and showcase for the bigger services mission – as Alan Kay once said, “people who are really serious about software should make their own hardware” – and its revenues should trend peristaltically higher.  And finally there’s Consulting and product support, which contributes around $5.6bn in revenue today.  Neither of these businesses are meaningful value drivers.  They exist in service to the software.  All these numbers are so big in absolute terms that it feels both farcical and disrespectful to throw them around flippantly.

The company will churn out at least $30bn of free cash flow every year in the meantime, creating half the company’s current market cap in a decade.  The company obviously did not have the best capital allocation record under Ballmer, but from what I can tell, this really is a new, more collaborative Microsoft, focused as hell on marrying technology and “jobs to be done” and adapting to new computing paradigms while simultaneously pushing its own unique advantages within them to claim value for itself.